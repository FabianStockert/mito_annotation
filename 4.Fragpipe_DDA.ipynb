{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6169b07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  # For working with data in tabular format\n",
    "import numpy as np  # For numerical computations\n",
    "import matplotlib.pyplot as plt  # For creating plots and visualizations\n",
    "from matplotlib_venn import venn2  # For creating Venn diagrams\n",
    "import plotly.express as px  # For interactive visualizations\n",
    "import os  # For folder generation\n",
    "import statistics  # For statistical computations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9065778",
   "metadata": {},
   "source": [
    "The next cell is tailored specifically for handling and combining _ion_label_quant.tsv output files from FragPipe. \n",
    "If you have a different single output file format, you can load and process it in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f471afc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_prefixes_input = input('Enter the file prefixes, before \"_ion_label_quant.tsv\", separated by commas: ').strip().split(',')\n",
    "file_prefixes = [prefix.strip() for prefix in file_prefixes_input]\n",
    "\n",
    "\n",
    "directory = input(\"Enter the directory to save intermediate files (default: 'intermediate_files'): \").strip()\n",
    "if not directory:\n",
    "    directory = 'intermediate_files'\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "def main():\n",
    "    global directory\n",
    "\n",
    "    # Processing and aggregating data for each file prefix\n",
    "    for prefix in file_prefixes:\n",
    "        try:\n",
    "            # Read the original file using pandas read_csv function\n",
    "            df = pd.read_csv(f\"{prefix}_ion_label_quant.tsv\", sep='\\t')\n",
    "        except FileNotFoundError:\n",
    "            print(f\"File not found: {prefix}_ion_label_quant.tsv\")\n",
    "            continue\n",
    "\n",
    "        # Combine the same peptides with different charge states and possible oxidation on methionine\n",
    "        df['Modified Peptide'] = df['Modified Peptide'].str.replace(r'\\[15\\.9949\\]', '', regex=True)\n",
    "\n",
    "        # Group the DataFrame by specified columns and sum the intensity columns\n",
    "        grouped_df = df.groupby(['Peptide Sequence', 'Modified Peptide', 'Peptide Length', 'Protein ID', 'Protein Description', 'Label Count']).agg({\n",
    "            'Light Intensity': 'sum',  # Sum the 'Light Intensity' column\n",
    "            'Heavy Intensity': 'sum'   # Sum the 'Heavy Intensity' column\n",
    "        }).reset_index()  # Reset the index of the resulting DataFrame\n",
    "\n",
    "        # Replace 0 values with NaN in intensity columns\n",
    "        columns_to_replace = ['Light Intensity', 'Heavy Intensity']\n",
    "        grouped_df[columns_to_replace] = grouped_df[columns_to_replace].replace(0, np.nan)\n",
    "\n",
    "        # Calculate log2 ratios of 'Heavy Intensity' divided by 'Light Intensity'\n",
    "        grouped_df['Log2 Ratio HL_new'] = np.log2(grouped_df['Heavy Intensity'] / grouped_df['Light Intensity'])\n",
    "\n",
    "        # Define the file path for saving\n",
    "        file_path = os.path.join(directory, f\"{prefix}_df_max_label_count_newlog2.tsv\")\n",
    "\n",
    "        # Save the updated DataFrame to a new file with a modified file prefix\n",
    "        grouped_df.to_csv(file_path, sep='\\t', index=False)\n",
    "\n",
    "        # Notify the user about the saved file\n",
    "        print(f\"Processed and saved: {file_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "# Create an empty list to store DataFrames\n",
    "dfs = []\n",
    "\n",
    "# Iterate over each file prefix\n",
    "for prefix in file_prefixes:\n",
    "    file_path = os.path.join(directory, f\"{prefix}_df_max_label_count_newlog2.tsv\")  # Construct the file path\n",
    "\n",
    "    # Read the file\n",
    "    df = pd.read_csv(file_path, sep='\\t')\n",
    "\n",
    "    # Select specific columns\n",
    "    df = df[['Peptide Sequence', 'Modified Peptide', 'Peptide Length', 'Protein ID', 'Protein Description', 'Label Count']]\n",
    "\n",
    "    # Append the DataFrame to the list of DataFrames\n",
    "    dfs.append(df)\n",
    "\n",
    "# Combine entries with the same \"Modified Peptide\", \"Protein ID\", and \"Charge\"\n",
    "combined_df = pd.concat(dfs).drop_duplicates()\n",
    "\n",
    "def process_ion_label_quant(df, prefix):\n",
    "    # Select specific columns from the dataframe\n",
    "    df = df[['Log2 Ratio HL_new', 'Modified Peptide', 'Protein ID', 'Label Count', 'Light Intensity', 'Heavy Intensity']].copy()\n",
    "\n",
    "    # Rename columns based on the provided prefix\n",
    "    df = df.rename(columns={\n",
    "        'Log2 Ratio HL_new': f'Log2 Ratio HL_new {prefix}',\n",
    "        'Light Intensity': f'Light Intensity {prefix}',\n",
    "        'Heavy Intensity': f'Heavy Intensity {prefix}',\n",
    "        'Modified Peptide': f'Modified Peptide {prefix}'})\n",
    "\n",
    "    return df\n",
    "\n",
    "# Define a function to merge dataframes based on specific columns\n",
    "def merge_dfs(combined_df, df, prefix):\n",
    "    # Merge dataframes on specified columns and drop redundant columns\n",
    "    merged_df = pd.merge(combined_df, df,\n",
    "                         left_on=['Modified Peptide', 'Protein ID', 'Label Count'],\n",
    "                         right_on=[f'Modified Peptide {prefix}', 'Protein ID', 'Label Count'],\n",
    "                         how='left')\n",
    "    return merged_df.drop([f'Modified Peptide {prefix}'], axis=1)\n",
    "\n",
    "# Loop through each file prefix\n",
    "for prefix in file_prefixes:\n",
    "    # Read ion label quant data from file\n",
    "    ion_label_quant_df = pd.read_csv(os.path.join(directory, f\"{prefix}_df_max_label_count_newlog2.tsv\"), sep='\\t')\n",
    "    # Print the number of peptides in the dataframe\n",
    "    print(f\"{len(ion_label_quant_df)} Anzahl der Peptide in {prefix}_df_max_label_count_newlog2\")\n",
    "\n",
    "    # Process ion label quant data and rename columns\n",
    "    processed_df = process_ion_label_quant(ion_label_quant_df, prefix)\n",
    "\n",
    "    # Merge dataframes based on specific columns\n",
    "    combined_df = merge_dfs(combined_df, processed_df, prefix)\n",
    "\n",
    "# Define a custom aggregation function to keep the row with the maximum \"Label Count\"\n",
    "def keep_max_label_count(rows):\n",
    "    # Find the index of the row with the maximum \"Label Count\"\n",
    "    max_label_count_index = rows['Label Count'].idxmax()\n",
    "    # Return the entire row corresponding to the maximum \"Label Count\"\n",
    "    return rows.loc[max_label_count_index]\n",
    "\n",
    "# Apply the custom aggregation function to keep the row with the maximum \"Label Count\" for each group\n",
    "combined_df_max_label_count = combined_df.groupby(['Peptide Sequence', 'Modified Peptide', 'Peptide Length', 'Protein ID', 'Protein Description']).apply(keep_max_label_count).reset_index(drop=True)\n",
    "\n",
    "# Print the number of peptides in the final combined dataframe\n",
    "print(f\"{len(combined_df_max_label_count)} Peptide combined_df_max_label_count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ddadbf",
   "metadata": {},
   "source": [
    "Start here if you already have a file containing different replicates, which is the case when MBR is enabled and there are no technical replicates. Change this part of the code: \"pd.read_csv(f\"{prefix}_ion_label_quant.tsv\", sep='\\t')\" and \"input('Enter the file prefixes, before \"_ion_label_quant.tsv\", separated by commas\" to your filename. You need to work with a prefix to be able to run the other cells. \n",
    "\n",
    "Click on the next cell, select \"Cell\" in the bar, then \"Cell type\" and \"Code\""
   ]
  },
  {
   "cell_type": "raw",
   "id": "98270121",
   "metadata": {},
   "source": [
    "file_prefixes_input = input('Enter the file prefixes, before \"_ion_label_quant.tsv\", separated by commas: ').strip().split(',')\n",
    "file_prefixes = [prefix.strip() for prefix in file_prefixes_input]\n",
    "\n",
    "# Load the specified file into a DataFrame\n",
    "for prefix in file_prefixes:\n",
    "    combined_df_max_label_count = pd.read_csv(f\"{prefix}_ion_label_quant.tsv\", sep='\\t')\n",
    "\n",
    "# Print a message to confirm successful loading\n",
    "print(f\"Loaded data from {file_prefixes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c65656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removal of pyro_glu and loss of ammonia on Cys\n",
    "default_substrings = \"-17.0266,-18.0106\"\n",
    "\n",
    "# Get user input and use default values if the input is empty\n",
    "substrings_input = input(f\"Enter pyro_Glu modifications in 'Modified Peptide', separated by commas (default: {default_substrings}): \").strip()\n",
    "substrings = substrings_input.split(',') if substrings_input else default_substrings.split(',')\n",
    "\n",
    "# Create a boolean mask for rows that do not contain any of the specified substrings in'Modified Peptide'\n",
    "mask = ~combined_df_max_label_count['Modified Peptide'].str.contains('|'.join(substrings), case=False, na=False)\n",
    "\n",
    "# Apply the mask to get a subset of the DataFrame\n",
    "combined_df_without_pyro = combined_df_max_label_count[mask].copy()\n",
    "\n",
    "# Print the number of peptides without the specified substrings in 'Modified Peptide'\n",
    "print(f\"{len(combined_df_without_pyro)} Peptides without pyro-Glu\\n\")\n",
    "\n",
    "# Reset the index of the DataFrame\n",
    "combined_df_without_pyro = combined_df_without_pyro.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051fd4b7",
   "metadata": {},
   "source": [
    "Normally this cell is not needed and just used for the reanalyis of a part of the published TAILS N-terminome dataset (Hofsetz et al., 2020).\n",
    "Only execute this cell, if you have technical replicates of biological replicates \n",
    "and you want to combine the intensities, otherwise skip it. This may be the case for ion_label_quant.tsv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4ba61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adjust the prefixes\n",
    "file_prefixes = [\n",
    "    '170123_Eddy_TAILS-1_10_ST_GA9_01_1465', '170119_Eddy_TAILS-1_10_ST_GA9_01_1415',\n",
    "    '170123_Eddy_TAILS-2_10_ST_GA10_01_1466', '170119_Eddy_TAILS-2_10_ST_GA10_01_1416',\n",
    "    '170123_Eddy_TAILS-3_10_ST_GA11_01_1464', '170119_Eddy_TAILS-3_10_ST_GA11_01_1417'\n",
    "]\n",
    "\n",
    "# Drop specific 'Log2 Ratio' columns\n",
    "log2_ratio_columns_to_drop = [f'Log2 Ratio HL_new {prefix}' for prefix in file_prefixes]\n",
    "combined_df_without_pyro = combined_df_without_pyro.drop(log2_ratio_columns_to_drop, axis=1, errors='ignore')\n",
    "\n",
    "# Define a function to combine intensities for a specific prefix\n",
    "def combine_intensities(df, prefix1, prefix2, prefix_name):\n",
    "    # Combine intensities for Light and Heavy\n",
    "    df[f'Light Intensity {prefix_name}_combined'] = df[f'Light Intensity {prefix1}'] + df[f'Light Intensity {prefix2}']\n",
    "    df[f'Heavy Intensity {prefix_name}_combined'] = df[f'Heavy Intensity {prefix1}'] + df[f'Heavy Intensity {prefix2}']\n",
    "    \n",
    "    # Remove original Light and Heavy Intensity columns\n",
    "    df.drop([f'Light Intensity {prefix1}', f'Light Intensity {prefix2}', f'Heavy Intensity {prefix1}', f'Heavy Intensity {prefix2}'], axis=1, inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Use prefixes to combine intensities\n",
    "for i in range(0, len(file_prefixes), 2):\n",
    "    combined_df_without_pyro = combine_intensities(combined_df_without_pyro, file_prefixes[i], file_prefixes[i+1], f'TAILS{(i//2)+1}')\n",
    "\n",
    "# Define a function to calculate log2 ratios for a specific prefix\n",
    "def calculate_log2_ratios(df, prefix):\n",
    "    # Calculate log2 ratios for the specified intensities\n",
    "    columns_to_replace = [f'Light Intensity {prefix}', f'Heavy Intensity {prefix}']\n",
    "    df[columns_to_replace] = df[columns_to_replace].replace(0, np.nan)\n",
    "    df[f'Log2 Ratio {prefix} Heavy/Light'] = np.log2(df[f'Heavy Intensity {prefix}'] / df[f'Light Intensity {prefix}'])\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Use combined prefixes to calculate log2 ratios\n",
    "combined_prefixes = [f'TAILS{i+1}_combined' for i in range(len(file_prefixes)//2)]\n",
    "for prefix in combined_prefixes:\n",
    "    combined_df_without_pyro = calculate_log2_ratios(combined_df_without_pyro, prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ced34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The next line is necessary if using isoforms\n",
    "# combined_df_without_pyro['Protein ID'] = combined_df_without_pyro['Protein ID'].str.split('-').str[0]\n",
    "\n",
    "# Create a directory for storing figures if it doesn't exist\n",
    "figures_dir = \"Figures\"\n",
    "if not os.path.exists(figures_dir):\n",
    "    os.makedirs(figures_dir)\n",
    "\n",
    "# Merge with fasta file\n",
    "fasta_file = input(\"Please enter the path of the tsv file originating from the organism specific FASTA file (e.g., Mus_musculus_Mouse_canonical_2024_03_06.tsv): \")\n",
    "while not os.path.exists(fasta_file):\n",
    "    print(\"File not found. Please enter a valid file path.\")\n",
    "    fasta_file = input(\"Please enter the path to the FASTA file (e.g., Mus_musculus_Mouse_canonical_2024_03_06.tsv): \")\n",
    "\n",
    "# Read in the fasta file\n",
    "fasta_df = pd.read_csv(fasta_file, sep='\\t')\n",
    "\n",
    "# Select the 'seq' column from gene_info_df\n",
    "gene_seq_df = fasta_df[['Protein Id', 'seq']]\n",
    "\n",
    "# Merge dataframes based on 'Protein ID'\n",
    "combined_df_without_pyro_fasta = pd.merge(combined_df_without_pyro, gene_seq_df, left_on='Protein ID', right_on='Protein Id', how='inner')\n",
    "\n",
    "# Find the position of 'Peptide Sequence' in 'seq' and calculate start and end positions\n",
    "combined_df_without_pyro_fasta['Start_Position_in_seq-1'] = combined_df_without_pyro_fasta.apply(lambda row: row['seq'].find(row['Peptide Sequence']), axis=1)\n",
    "combined_df_without_pyro_fasta['Start_Position_in_seq'] = combined_df_without_pyro_fasta['Start_Position_in_seq-1'] + 1\n",
    "combined_df_without_pyro_fasta['End_Position_in_seq-1'] = combined_df_without_pyro_fasta.apply(lambda row: row['Start_Position_in_seq'] + len(row['Peptide Sequence']), axis=1)\n",
    "combined_df_without_pyro_fasta['End_Position_in_seq'] = combined_df_without_pyro_fasta['End_Position_in_seq-1'] - 1\n",
    "\n",
    "# Extract 1 amino acid before 'Peptide Sequence' and create a new column 'Amino_acid_before_Sequence'\n",
    "combined_df_without_pyro_fasta['Amino_acid_before_Sequence'] = combined_df_without_pyro_fasta.apply(lambda row: row['seq'][row['Start_Position_in_seq-1'] - 1:row['Start_Position_in_seq-1']], axis=1)\n",
    "\n",
    "# Extract 6 amino acids before 'Peptide Sequence' and create a new column '6_Amino_acids_before_Sequence'\n",
    "combined_df_without_pyro_fasta['6_Amino_acids_before_Sequence'] = combined_df_without_pyro_fasta.apply(lambda row: row['seq'][row['Start_Position_in_seq-1'] - 6:row['Start_Position_in_seq-1']], axis=1)\n",
    "\n",
    "# Create a 'cleavage_window' column by concatenating the last 6 characters of '6_Amino_acids_before_Sequence' and the first 6 characters of 'Peptide Sequence'\n",
    "combined_df_without_pyro_fasta['cleavage_window'] = combined_df_without_pyro_fasta['6_Amino_acids_before_Sequence'].str[-6:] + combined_df_without_pyro_fasta['Peptide Sequence'].astype(str).str[:6]\n",
    "\n",
    "# Drop unnecessary columns\n",
    "combined_df_without_pyro_fasta = combined_df_without_pyro_fasta.drop(['End_Position_in_seq-1', 'Start_Position_in_seq-1'], axis=1)\n",
    "\n",
    "# Counting 'R' and 'K' in the 'Amino_acid_before_Sequence' column to calculate percentage of tryptic peptides\n",
    "count_R_K = combined_df_without_pyro_fasta['Amino_acid_before_Sequence'].str.count('[RK]')\n",
    "total_peptides = len(combined_df_without_pyro_fasta)\n",
    "percentage_R_K = (count_R_K.sum() / total_peptides) * 100\n",
    "not_tryptic = 100 - percentage_R_K\n",
    "\n",
    "# Data for the pie chart\n",
    "labels = ['tryptic', 'not tryptic']\n",
    "sizes = [percentage_R_K, not_tryptic]\n",
    "colors = ['grey', 'purple']\n",
    "explode = (0.1, 0)  # Explode the 1st slice (tryptic peptides)\n",
    "\n",
    "# Plotting the pie chart\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.pie(sizes, explode=explode, labels=labels, colors=colors, autopct='%1.2f%%', startangle=140, textprops={'fontsize': 16, 'color': 'black'})\n",
    "#plt.pie(sizes, explode=explode, colors=colors, startangle=140)\n",
    "plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "\n",
    "# Saving the pie chart\n",
    "plt.savefig(\"Figures/Tryptic_pie.pdf\", dpi=600)\n",
    "\n",
    "# Showing the pie chart\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37951e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge with targetp2 file\n",
    "# Read in the fasta file converted in script 2\n",
    "df_targetp2 = pd.read_csv(\"./mouse_summary_modified.targetp2\", sep='\\t')\n",
    "\n",
    "# Merge dataframes 'Log2_ratio_mean_fasta' and 'df_targetp2' based on 'Protein ID' and 'ID'\n",
    "targetp2_merged_df = pd.merge(combined_df_without_pyro_fasta, df_targetp2, left_on='Protein ID', right_on='# ID', how='left')\n",
    "\n",
    "# Extract the number between \"CS pos:\" and \"-\" from the 'Combined_CS' column\n",
    "targetp2_merged_df['Start_Position_targetp2'] = targetp2_merged_df['Combined_CS'].str.extract(r'CS pos: \\d+-(\\d+)\\.')\n",
    "\n",
    "# Convert the extracted number to numeric type, handling errors by converting them to NaN\n",
    "targetp2_merged_df['Start_Position_targetp2'] = pd.to_numeric(targetp2_merged_df['Start_Position_targetp2'], errors='coerce')\n",
    "\n",
    "# Create a new column 'Start_targetp2_equal_Start_observed' based on the condition\n",
    "targetp2_merged_df['Start_targetp2_equal_Start_observed'] = np.where(\n",
    "    targetp2_merged_df['Start_Position_targetp2'] == targetp2_merged_df['Start_Position_in_seq'],\n",
    "    True, False)\n",
    "\n",
    "# Remove entries where 'Start_Position_in_seq' is 0, as the sequence does not belong to the Protein\n",
    "targetp2_merged_df = targetp2_merged_df[targetp2_merged_df['Start_Position_in_seq'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2e75fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a directory for storing figures if it doesn't exist\n",
    "figures_dir = \"Figures\"\n",
    "if not os.path.exists(figures_dir):\n",
    "    os.makedirs(figures_dir)\n",
    "\n",
    "# Filter DataFrame for rows where 'Start_Position_in_seq' is 1\n",
    "filtered_df = targetp2_merged_df[targetp2_merged_df['Start_Position_in_seq'].isin([1])]\n",
    "\n",
    "# Count the occurrences of each value in 'Start_Position_in_seq'\n",
    "value_counts1 = filtered_df['Start_Position_in_seq'].value_counts()\n",
    "\n",
    "# Filter DataFrame for rows where 'Start_Position_in_seq' is 2\n",
    "filtered_df2 = targetp2_merged_df[targetp2_merged_df['Start_Position_in_seq'].isin([2])]\n",
    "\n",
    "# Count the occurrences of each value in 'Start_Position_in_seq'\n",
    "value_counts2 = filtered_df2['Start_Position_in_seq'].value_counts()\n",
    "\n",
    "# Check if 'True' in 'Start_targetp2_equal_Start_observed' and 'MT' in 'Prediction'\n",
    "mt_counts = targetp2_merged_df[(targetp2_merged_df['Start_targetp2_equal_Start_observed'] == True) & (targetp2_merged_df['Prediction'] == 'MT')].shape[0]\n",
    "\n",
    "# Check if 'True' in 'Start_targetp2_equal_Start_observed' and 'SP' in 'Prediction'\n",
    "sp_counts = targetp2_merged_df[(targetp2_merged_df['Start_targetp2_equal_Start_observed'] == True) & (targetp2_merged_df['Prediction'] == 'SP')].shape[0]\n",
    "\n",
    "# Calculate the count for the remaining values ('NoN')\n",
    "non_counts = ((len(targetp2_merged_df) - (value_counts1.sum() + value_counts2.sum() + mt_counts + sp_counts)))\n",
    "\n",
    "# Create a list of values for plotting the bar chart\n",
    "bar_values = [value_counts1.get(1, 0), value_counts2.get(2, 0), mt_counts, sp_counts, non_counts]\n",
    "\n",
    "# Plotting the bar chart\n",
    "# Plotting the bar chart\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "bar_labels = [\"1\", \"2\", 'MTS', 'SP', 'non-canonical']\n",
    "\n",
    "# Define colors for the bars\n",
    "colors = [\"#FFD700\", \"#FF8C00\", 'red', 'green', 'gray']\n",
    "\n",
    "# Create bars with corresponding labels and colors\n",
    "bars = ax.bar(bar_labels, bar_values, color=colors)\n",
    "\n",
    "# Set chart title, x-axis label, and y-axis label\n",
    "plt.ylabel('Count', fontsize = 16)\n",
    "plt.xlabel('Position', fontsize = 16)\n",
    "\n",
    "# Set ylim for y-axis\n",
    "plt.ylim(0, max(bar_values) * 1.1)  # Adjust multiplier as needed\n",
    "\n",
    "# Customize y-axis tick labels\n",
    "ax.tick_params(axis='y', labelsize=16) \n",
    "# Customize x-axis tick labels\n",
    "ax.tick_params(axis='x', labelsize=16) \n",
    "\n",
    "# Remove left spine\n",
    "ax.spines['right'].set_visible(False)\n",
    "# Remove top spine\n",
    "ax.spines['top'].set_visible(False)\n",
    "\n",
    "# Add text labels on top of the bars indicating the count values\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, yval, int(yval), ha='center', va='bottom',fontsize=16)\n",
    "\n",
    "output_file = os.path.join(figures_dir, \"histograms_position.pdf\")\n",
    "plt.savefig(output_file, dpi=600)\n",
    "# Display the bar chart\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfbf6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter rows where the 'Prediction' column is 'MT'\n",
    "targetp2_MT_prediction = targetp2_merged_df[targetp2_merged_df[\"Prediction\"] == 'MT']  \n",
    "\n",
    "# Print the number of peptides matched with targetp2 and 'MT' as Prediction\n",
    "print(f\"{len(targetp2_MT_prediction)} Peptide matched with targetp2 and 'MT' as Prediction\")\n",
    "\n",
    "# Create a new column 'Modification_Status' based on conditions in 'Modified Peptide'\n",
    "targetp2_MT_prediction['Modification_Status'] = np.where(\n",
    "    targetp2_MT_prediction['Modified Peptide'].str.contains(\"42.0106\", case=False, na=False),\n",
    "    'Acetylated', 'Dimethylated')\n",
    "\n",
    "# Calculate the difference between 'Start_Position_in_seq' and 'Start_Position_targetp2' and create a new column\n",
    "targetp2_MT_prediction['Position_Difference'] = (\n",
    "    targetp2_MT_prediction['Start_Position_in_seq'] - \n",
    "    targetp2_MT_prediction['Start_Position_targetp2'])\n",
    "\n",
    "# Create a copy of the DataFrame for further processing\n",
    "targetp2_MT_prediction_copy = targetp2_MT_prediction.copy()\n",
    "\n",
    "# Filter rows where the absolute difference between 'Start_Position_targetp2' and 'Start_Position_in_seq' is <= 10\n",
    "condition = abs(targetp2_MT_prediction_copy['Start_Position_targetp2'] - targetp2_MT_prediction_copy['Start_Position_in_seq']) <= 10\n",
    "\n",
    "# Create a DataFrame with rows matching the condition\n",
    "targetp2_MT_prediction_plusminus10_df = targetp2_MT_prediction_copy.loc[condition].copy()\n",
    "targetp2_MT_prediction_plusminus10_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Print the number of peptides matched with targetp2 +/- 10 and 'MT' as Prediction\n",
    "print(f\"{len(targetp2_MT_prediction_plusminus10_df)} Peptide matched with targetp2 +/- 10 and 'MT' as Prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76d6efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Series with the complete range of values from -10 to 10 and fill missing values with zeros\n",
    "full_range = pd.Series(0, index=range(-10, 11))\n",
    "\n",
    "# Filter entries with \"Dimethylated\" status\n",
    "entries_dimethylated = targetp2_MT_prediction_plusminus10_df['Modification_Status'] == 'Dimethylated'\n",
    "\n",
    "# Count occurrences of each unique value for entries with \"Dimethylated\" status\n",
    "difference_counts_dimethylated = (\n",
    "    targetp2_MT_prediction_plusminus10_df[entries_dimethylated]['Position_Difference']\n",
    "    .value_counts()\n",
    "    .sort_index())\n",
    "\n",
    "# Reindex to the full range and fill missing values with 0\n",
    "difference_counts_dimethylated = difference_counts_dimethylated.reindex(full_range.index, fill_value=0)\n",
    "# Filter out bars with a count of 0\n",
    "difference_counts_dimethylated = difference_counts_dimethylated[difference_counts_dimethylated != 0]\n",
    "\n",
    "# Plotting the bar chart\n",
    "fig, ax = plt.subplots(figsize=(15, 6))\n",
    "\n",
    "# Plot bars for entries with \"Dimethylated\" status in blue\n",
    "bars1 = ax.bar(difference_counts_dimethylated.index, difference_counts_dimethylated.values, color='blue', label='Dimethylated')\n",
    "\n",
    "# Filter entries with \"Acetylated\" status\n",
    "entries_acetylated = targetp2_MT_prediction_plusminus10_df['Modification_Status'] == 'Acetylated'\n",
    "\n",
    "# Count occurrences of each unique value for entries with \"Acetylated\" status\n",
    "difference_counts_acetylated = (\n",
    "    targetp2_MT_prediction_plusminus10_df[entries_acetylated]['Position_Difference']\n",
    "    .value_counts()\n",
    "    .sort_index())\n",
    "\n",
    "# Reindex to the full range and fill missing values with 0\n",
    "difference_counts_acetylated = difference_counts_acetylated.reindex(full_range.index, fill_value=0)\n",
    "# Filter out bars with a count of 0\n",
    "difference_counts_acetylated = difference_counts_acetylated[difference_counts_acetylated != 0]\n",
    "\n",
    "# Plot bars for entries with \"Acetylated\" status in grey\n",
    "#bars2 = ax.bar(difference_counts_acetylated.index, difference_counts_acetylated.values, color='grey', label='Acetylated')\n",
    "\n",
    "# Add labels with counts on top of each bar\n",
    "for bars, counts, color in zip([bars1], [difference_counts_dimethylated], ['blue']):\n",
    "    for bar, count in zip(bars, counts):\n",
    "        ax.text(\n",
    "            bar.get_x() + bar.get_width() / 2, \n",
    "            count, \n",
    "            str(count), \n",
    "            ha='center', \n",
    "            va='bottom', \n",
    "            color=color,\n",
    "            fontsize=14)\n",
    "\n",
    "ax.set_xlabel('Position Difference', fontsize=16)\n",
    "ax.set_ylabel('Count', fontsize=16)\n",
    "#ax.set_title('Start Position of measured Peptides by Acetylation Status (Measured - Predicted)')\n",
    "\n",
    "# Customize y-axis tick labels\n",
    "ax.tick_params(axis='y', labelsize=14) \n",
    "# Customize x-axis tick labels\n",
    "ax.tick_params(axis='x', labelsize=14) \n",
    "\n",
    "# Remove left spine\n",
    "ax.spines['right'].set_visible(False)\n",
    "# Remove top spine\n",
    "ax.spines['top'].set_visible(False)\n",
    "\n",
    "# Set integer ticks on the x-axis\n",
    "plt.xticks([int(x) for x in difference_counts_dimethylated.index])\n",
    "\n",
    "# Add legend\n",
    "plt.legend(fontsize=14, loc='upper left', frameon=False)\n",
    "# Save the plot as a PNG file with higher resolution\n",
    "plt.savefig(\"Figures/histograms_measured-predicted.pdf\", dpi=600)\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f76727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter entries in Matched_with_targetp2_plusminus10_df where Position_Difference is 0\n",
    "entries_zero = targetp2_MT_prediction_plusminus10_df[targetp2_MT_prediction_plusminus10_df['Position_Difference'] == 0]\n",
    "\n",
    "# Filter entries in entries_zero DataFrame based on Acetylation_Status\n",
    "dimethylated_entries = entries_zero[entries_zero['Modification_Status'] == 'Dimethylated']\n",
    "acetylated_entries = entries_zero[entries_zero['Modification_Status'] == 'Acetylated']\n",
    "\n",
    "# Get the sets of unique peptide sequences for dimethylated and acetylated entries\n",
    "dimethylated_set = set(dimethylated_entries['Peptide Sequence'])\n",
    "acetylated_set = set(acetylated_entries['Peptide Sequence'])\n",
    "\n",
    "# Define colors for dimethylated (blue) and acetylated (grey) sets\n",
    "dimethylated_color = (0, 0, 1)\n",
    "acetylated_color = 'grey'\n",
    "\n",
    "# Create a Venn diagram with custom colors using matplotlib_venn\n",
    "venn = venn2([dimethylated_set, acetylated_set], set_labels=('Dimethylated', 'Acetylated'), set_colors=(dimethylated_color, acetylated_color))\n",
    "\n",
    "# Increase font size of numbers\n",
    "for text in venn.set_labels:\n",
    "    text.set_fontsize(16)  # Adjust font size as needed\n",
    "\n",
    "for text in venn.subset_labels:\n",
    "    text.set_fontsize(16)  # Adjust font size as needed\n",
    "\n",
    "# Increase font size of subset labels\n",
    "for text in venn.subset_labels:\n",
    "    text.set_fontsize(16)  # Adjust font size as needed\n",
    "\n",
    "# Save the Venn diagram as a PNG file with higher resolution\n",
    "plt.savefig(\"Figures/venn_diagram_at_position_0.png\", dpi=600)\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1907cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tsv files with cleavage window for ice logo generation\n",
    "# Pepitdes that are modified differently can be filtered in the tsv file\n",
    "\n",
    "output_folder = \"tsv_files_for_Ice_logo_generation\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Select rows where the difference between 'Start_Position_in_seq' and 'Start_Position_targetp2' is 0\n",
    "targetp2_MT_prediction_plusminus10_df_0 = targetp2_MT_prediction_plusminus10_df[\n",
    "    (targetp2_MT_prediction_plusminus10_df['Start_Position_in_seq'] - targetp2_MT_prediction_plusminus10_df['Start_Position_targetp2']) == 0]\n",
    "# Save the resulting dataframe to a TSV file\n",
    "output_path_0 = os.path.join(output_folder, \"targetp2_MT_prediction_plusminus10_df_0.tsv\")\n",
    "targetp2_MT_prediction_plusminus10_df_0.to_csv(output_path_0, sep='\\t', index=False)\n",
    "# Print the length (number of rows) of the dataframe\n",
    "print(len(targetp2_MT_prediction_plusminus10_df_0))\n",
    "\n",
    "# Rows where the difference between 'Start_Position_in_seq' and 'Start_Position_targetp2' is 1\n",
    "targetp2_MT_prediction_plusminus10_df_1 = targetp2_MT_prediction_plusminus10_df[\n",
    "    (targetp2_MT_prediction_plusminus10_df['Start_Position_in_seq'] - targetp2_MT_prediction_plusminus10_df['Start_Position_targetp2']) == 1]\n",
    "output_path_1 = os.path.join(output_folder, \"targetp2_MT_prediction_plusminus10_df_1.tsv\")\n",
    "targetp2_MT_prediction_plusminus10_df_1.to_csv(output_path_1, sep='\\t', index=False)\n",
    "print(len(targetp2_MT_prediction_plusminus10_df_1))\n",
    "\n",
    "# Rows where the difference between 'Start_Position_in_seq' and 'Start_Position_targetp2' is -1\n",
    "targetp2_MT_prediction_plusminus10_df_minus1 = targetp2_MT_prediction_plusminus10_df[\n",
    "    (targetp2_MT_prediction_plusminus10_df['Start_Position_in_seq'] - targetp2_MT_prediction_plusminus10_df['Start_Position_targetp2']) == -1]\n",
    "output_path_minus1 = os.path.join(output_folder, \"targetp2_MT_prediction_plusminus10_df_minus1.tsv\")\n",
    "targetp2_MT_prediction_plusminus10_df_minus1.to_csv(output_path_minus1, sep='\\t', index=False)\n",
    "print(len(targetp2_MT_prediction_plusminus10_df_minus1))\n",
    "\n",
    "\n",
    "# Filter rows where 'cleavage_window' has 'R' at the fifth position\n",
    "filtered_df = targetp2_MT_prediction_plusminus10_df_0[\n",
    "    targetp2_MT_prediction_plusminus10_df_0['cleavage_window'].str[4] == 'R']\n",
    "# Save the resulting DataFrame to a TSV file\n",
    "output_path_1 = os.path.join(output_folder, \"targetp2_MT_prediction_plusminus10_df_0_R_at_P-2.tsv\")\n",
    "filtered_df.to_csv(output_path_1, sep='\\t', index=False)\n",
    "# Print the length of the filtered DataFrame\n",
    "print(len(filtered_df))\n",
    "\n",
    "# Filter rows where 'cleavage_window' has 'R' at the fourth position\n",
    "filtered_df2 = targetp2_MT_prediction_plusminus10_df_0[\n",
    "    targetp2_MT_prediction_plusminus10_df_0['cleavage_window'].str[3] == 'R']\n",
    "output_path_2 = os.path.join(output_folder, \"targetp2_MT_prediction_plusminus10_df_0_R_at_P-3.tsv\")\n",
    "filtered_df2.to_csv(output_path_2, sep='\\t', index=False)\n",
    "print(len(filtered_df2))\n",
    "\n",
    "# Filter rows where 'cleavage_window' has 'R' at the third position\n",
    "filtered_df3 = targetp2_MT_prediction_plusminus10_df_1[\n",
    "    targetp2_MT_prediction_plusminus10_df_1['cleavage_window'].str[2] == 'R']\n",
    "output_path_3 = os.path.join(output_folder, \"targetp2_MT_prediction_plusminus10_df_1_R_at_P-4.tsv\")\n",
    "filtered_df3.to_csv(output_path_3, sep='\\t', index=False)\n",
    "print(len(filtered_df3))\n",
    "\n",
    "# Filter rows where 'cleavage_window' has 'R' at the fourth position\n",
    "filtered_df4 = targetp2_MT_prediction_plusminus10_df_1[\n",
    "    targetp2_MT_prediction_plusminus10_df_1['cleavage_window'].str[3] == 'R']\n",
    "output_path_4 = os.path.join(output_folder, \"targetp2_MT_prediction_plusminus10_df_1_R_at_P-3.tsv\")\n",
    "filtered_df4.to_csv(output_path_4, sep='\\t', index=False)\n",
    "print(len(filtered_df4))\n",
    "\n",
    "# Filter rows where 'cleavage_window' has 'R' at the third position\n",
    "filtered_df5 = targetp2_MT_prediction_plusminus10_df_minus1[\n",
    "    targetp2_MT_prediction_plusminus10_df_minus1['cleavage_window'].str[4] == 'R']\n",
    "output_path_5 = os.path.join(output_folder, \"targetp2_MT_prediction_plusminus10_df_minus1_R_at_P-2.tsv\")\n",
    "filtered_df5.to_csv(output_path_5, sep='\\t', index=False)\n",
    "print(len(filtered_df5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670366d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the first letter from \"Peptide Sequence\" in Matched_with_targetp2_plusminus10_df_minus1\n",
    "targetp2_MT_prediction_plusminus10_df_minus1['Peptide Sequence'] = targetp2_MT_prediction_plusminus10_df_minus1['Peptide Sequence'].str[1:]\n",
    "\n",
    "# Get the sets of unique peptide sequences for dimethylated and acetylated entries\n",
    "minus1_set = set(targetp2_MT_prediction_plusminus10_df_minus1['Peptide Sequence'])\n",
    "zero_set = set(targetp2_MT_prediction_plusminus10_df_0['Peptide Sequence'])\n",
    "\n",
    "# Define colors\n",
    "minus1_set_color = 'yellow'\n",
    "zero_set_color = 'green'\n",
    "\n",
    "# Create a Venn diagram with custom colors\n",
    "venn2([minus1_set, zero_set], set_labels=('Measured - Predicted = -1', 'Measured - Predicted = 0'), set_colors=(minus1_set_color, zero_set_color))\n",
    "\n",
    "# Display the plot\n",
    "plt.title('Number of Peptides in Measured - Predicted = 0 that are part of peptides in Measured - Predicted = -1')\n",
    "plt.savefig(\"Figures/venn_diagram_0_and_-1.pdf\", dpi=600)  # Save as PNG with higher resolution\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4a2a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming targetp2_MT_prediction is already defined and is a DataFrame\n",
    "targetp2_MT_prediction_filtered = targetp2_MT_prediction\n",
    "\n",
    "# Configure pandas to display all columns\n",
    "pd.set_option('display.max_columns', None)  # None means no limit\n",
    "display(targetp2_MT_prediction_filtered)\n",
    "\n",
    "# Interactive input for column names\n",
    "subset_1_cols_input = input(\n",
    "    'Enter the column names for log2 ratios, separated by commas, which can be found in the data frame below: '\n",
    ")\n",
    "subset_1_cols = [col.strip() for col in subset_1_cols_input.split(',')]\n",
    "\n",
    "# Interactive input for the number of replicates\n",
    "num_replicates_input = input(\n",
    "    'Enter the number of replicates in which the ratio should be present (e.g., 2): '\n",
    ")\n",
    "num_replicates = int(num_replicates_input)\n",
    "\n",
    "# Interactive input for the total number of replicates (default to 3)\n",
    "total_replicates_input = input(\n",
    "    'Enter the total number of replicates (e.g., 3): '\n",
    ")\n",
    "total_replicates = int(total_replicates_input) if total_replicates_input else 3\n",
    "\n",
    "# Combine conditions with logical OR operator\n",
    "combined_condition = (\n",
    "    (targetp2_MT_prediction_filtered[subset_1_cols].notna().sum(axis=1) >= num_replicates)\n",
    ")\n",
    "\n",
    "# Apply combined condition to filter the dataframe\n",
    "targetp2_MT_prediction_filtered = targetp2_MT_prediction_filtered[combined_condition].copy()\n",
    "\n",
    "# Further filter rows where \"Prediction\" is 'MT'\n",
    "targetp2_MT_prediction_filtered = targetp2_MT_prediction_filtered[targetp2_MT_prediction_filtered[\"Prediction\"] == 'MT']\n",
    "print(f\"{len(targetp2_MT_prediction_filtered)} Peptides matched with targetp2, present in {num_replicates} out of {total_replicates} replicates and 'MT' as Prediction\")\n",
    "targetp2_MT_prediction_filtered.to_csv('file_for_R_script.txt', sep='\\t', index=False)\n",
    "\n",
    "# Create a copy of the dataframe\n",
    "targetp2_MT_prediction_filtered = targetp2_MT_prediction_filtered.copy()\n",
    "\n",
    "# Interactive input for the absolute difference threshold\n",
    "diff_threshold_input = input(\n",
    "    'Enter the absolute difference threshold for positions (e.g., 10): '\n",
    ")\n",
    "diff_threshold = int(diff_threshold_input)\n",
    "\n",
    "# Filter rows where the absolute difference between 'Start_Position_targetp2' and 'Start_Position_in_seq' is <= the specified threshold\n",
    "condition = abs(targetp2_MT_prediction_filtered['Start_Position_targetp2'] - targetp2_MT_prediction_filtered['Start_Position_in_seq']) <= diff_threshold\n",
    "targetp2_MT_prediction_filtered_plusminus = targetp2_MT_prediction_filtered.loc[condition].copy()\n",
    "targetp2_MT_prediction_filtered_plusminus.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Print the number of matched peptides\n",
    "print(f\"{len(targetp2_MT_prediction_filtered_plusminus)} Peptides matched with targetp2 +/- {diff_threshold}, present in {num_replicates} out of {total_replicates} replicates and 'MT' as Prediction\")\n",
    "\n",
    "# Create a dynamic filename based on user inputs\n",
    "filename = f\"targetp2_MT_prediction_{num_replicates}_out_of_{total_replicates}_replicates_plusminus{diff_threshold}.tsv\"\n",
    "\n",
    "# Save the filtered dataframe to a TSV file\n",
    "targetp2_MT_prediction_filtered_plusminus.to_csv(filename, sep='\\t', index=False)\n",
    "\n",
    "print(f\"Filtered data saved to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e19d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the filename based on user inputs from the previous cell\n",
    "filename = f\"targetp2_MT_prediction_{num_replicates}_out_of_{total_replicates}_replicates_plusminus{diff_threshold}.tsv\"\n",
    "\n",
    "# Load the filtered DataFrame from the file\n",
    "targetp2_MT_prediction_filtered_plusminus = pd.read_csv(filename, sep='\\t')\n",
    "\n",
    "# Display the DataFrame\n",
    "pd.set_option('display.max_columns', None)  # None means no limit\n",
    "\n",
    "# Create a Series with the complete range of values from -10 to 10 and fill missing values with zeros\n",
    "full_range = pd.Series(0, index=range(-10, 11))\n",
    "\n",
    "# Filter entries with \"Dimethylated\" status\n",
    "entries_dimethylated = targetp2_MT_prediction_filtered_plusminus['Modification_Status'] == 'Dimethylated'\n",
    "\n",
    "# Count occurrences of each unique value for entries with \"Dimethylated\" status\n",
    "difference_counts_dimethylated = (\n",
    "    targetp2_MT_prediction_filtered_plusminus[entries_dimethylated]['Position_Difference']\n",
    "    .value_counts()\n",
    "    .sort_index())\n",
    "\n",
    "# Reindex to the full range and fill missing values with 0\n",
    "difference_counts_dimethylated = difference_counts_dimethylated.reindex(full_range.index, fill_value=0)\n",
    "\n",
    "# Filter out bars with a count of 0\n",
    "# difference_counts_dimethylated = difference_counts_dimethylated[difference_counts_dimethylated != 0]\n",
    "\n",
    "# Plotting the bar chart\n",
    "fig, ax = plt.subplots(figsize=(15, 6))\n",
    "\n",
    "# Plot bars for entries with \"Dimethylated\" status in blue\n",
    "bars1 = ax.bar(difference_counts_dimethylated.index, difference_counts_dimethylated.values, color='blue', label='Dimethylated')\n",
    "\n",
    "# Filter entries with \"Acetylated\" status\n",
    "entries_acetylated = targetp2_MT_prediction_filtered_plusminus['Modification_Status'] == 'Acetylated'\n",
    "\n",
    "# Count occurrences of each unique value for entries with \"Acetylated\" status\n",
    "difference_counts_acetylated = (\n",
    "    targetp2_MT_prediction_filtered_plusminus[entries_acetylated]['Position_Difference']\n",
    "    .value_counts()\n",
    "    .sort_index())\n",
    "\n",
    "# Reindex to the full range and fill missing values with 0\n",
    "difference_counts_acetylated = difference_counts_acetylated.reindex(full_range.index, fill_value=0)\n",
    "\n",
    "# Filter out bars with a count of 0\n",
    "difference_counts_acetylated = difference_counts_acetylated[difference_counts_acetylated != 0]\n",
    "\n",
    "\n",
    "# Plot bars for entries with \"Acetylated\" status in red\n",
    "#bars2 = ax.bar(difference_counts_acetylated.index, difference_counts_acetylated.values, color='orange', label='Acetylated')\n",
    "\n",
    "# Add labels with counts on top of each bar\n",
    "for bars, counts, color in zip([bars1], [difference_counts_dimethylated], ['blue']):\n",
    "    for bar, count in zip(bars, counts):\n",
    "        ax.text(\n",
    "            bar.get_x() + bar.get_width() / 2, \n",
    "            count, \n",
    "            str(count), \n",
    "            ha='center', \n",
    "            va='bottom', \n",
    "            color=color,\n",
    "            fontsize=14)\n",
    "\n",
    "ax.set_xlabel('Position Difference', fontsize=16)\n",
    "ax.set_ylabel('Count', fontsize=16)\n",
    "#ax.set_title('Start Position of measured Peptides by Acetylation Status (Measured - Predicted)')\n",
    "\n",
    "# Customize y-axis tick labels\n",
    "ax.tick_params(axis='y', labelsize=14) \n",
    "# Customize x-axis tick labels\n",
    "ax.tick_params(axis='x', labelsize=14) \n",
    "\n",
    "# Remove left spine\n",
    "ax.spines['right'].set_visible(False)\n",
    "# Remove top spine\n",
    "ax.spines['top'].set_visible(False)\n",
    "\n",
    "# Set integer ticks on the x-axis\n",
    "plt.xticks([int(x) for x in difference_counts_dimethylated.index])\n",
    "# Add legend\n",
    "plt.legend(fontsize=14, loc='upper left', frameon=False)\n",
    "# Save the plot as a PNG file with higher resolution\n",
    "plt.savefig(\"Figures/histograms_measured-predicted_filtered.pdf\", dpi=600)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Save the DataFrame to a TSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49aeb330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming the previous cell has defined these variables\n",
    "filename = f\"targetp2_MT_prediction_{num_replicates}_out_of_{total_replicates}_replicates_plusminus{diff_threshold}.tsv\"\n",
    "\n",
    "# Load the filtered DataFrame from the file\n",
    "targetp2_MT_prediction_filtered_plusminus = pd.read_csv(filename, sep='\\t')\n",
    "\n",
    "# Define the output folder (make sure to adjust this path as needed)\n",
    "output_folder = \"tsv_files_for_Ice_logo_generation\"  # Replace with your actual output folder path\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# Select rows where the difference between 'Start_Position_in_seq' and 'Start_Position_targetp2' is 0\n",
    "targetp2_0 = targetp2_MT_prediction_filtered_plusminus[\n",
    "    (targetp2_MT_prediction_filtered_plusminus['Start_Position_in_seq'] - targetp2_MT_prediction_filtered_plusminus['Start_Position_targetp2']) == 0]\n",
    "output_path_0 = os.path.join(output_folder, f\"{filename.split('.')[0]}_0.tsv\")\n",
    "targetp2_0.to_csv(output_path_0, sep='\\t', index=False)\n",
    "print(len(targetp2_0))\n",
    "\n",
    "# Rows where the difference between 'Start_Position_in_seq' and 'Start_Position_targetp2' is 1\n",
    "targetp2_1 = targetp2_MT_prediction_filtered_plusminus[\n",
    "    (targetp2_MT_prediction_filtered_plusminus['Start_Position_in_seq'] - targetp2_MT_prediction_filtered_plusminus['Start_Position_targetp2']) == 1]\n",
    "output_path_1 = os.path.join(output_folder, f\"{filename.split('.')[0]}_1.tsv\")\n",
    "targetp2_1.to_csv(output_path_1, sep='\\t', index=False)\n",
    "print(len(targetp2_1))\n",
    "\n",
    "# Rows where the difference between 'Start_Position_in_seq' and 'Start_Position_targetp2' is -1\n",
    "targetp2_minus1 = targetp2_MT_prediction_filtered_plusminus[\n",
    "    (targetp2_MT_prediction_filtered_plusminus['Start_Position_in_seq'] - targetp2_MT_prediction_filtered_plusminus['Start_Position_targetp2']) == -1]\n",
    "output_path_minus1 = os.path.join(output_folder, f\"{filename.split('.')[0]}_minus1.tsv\")\n",
    "targetp2_minus1.to_csv(output_path_minus1, sep='\\t', index=False)\n",
    "print(len(targetp2_minus1))\n",
    "\n",
    "# Filter rows where 'cleavage_window' has 'R' at the fifth position in targetp2_0\n",
    "filtered_df = targetp2_0[\n",
    "    targetp2_0['cleavage_window'].str[4] == 'R']\n",
    "output_path_filtered = os.path.join(output_folder, f\"{filename.split('.')[0]}_0_R_at_P-2.tsv\")\n",
    "filtered_df.to_csv(output_path_filtered, sep='\\t', index=False)\n",
    "print(len(filtered_df))\n",
    "\n",
    "# Filter rows where 'cleavage_window' has 'R' at the fourth position in targetp2_0\n",
    "filtered_df2 = targetp2_0[\n",
    "    targetp2_0['cleavage_window'].str[3] == 'R']\n",
    "output_path_filtered2 = os.path.join(output_folder, f\"{filename.split('.')[0]}_0_R_at_P-3.tsv\")\n",
    "filtered_df2.to_csv(output_path_filtered2, sep='\\t', index=False)\n",
    "print(len(filtered_df2))\n",
    "\n",
    "# Filter rows where 'cleavage_window' has 'R' at the third position in targetp2_1\n",
    "filtered_df3 = targetp2_1[\n",
    "    targetp2_1['cleavage_window'].str[2] == 'R']\n",
    "output_path_filtered3 = os.path.join(output_folder, f\"{filename.split('.')[0]}_1_R_at_P-4.tsv\")\n",
    "filtered_df3.to_csv(output_path_filtered3, sep='\\t', index=False)\n",
    "print(len(filtered_df3))\n",
    "\n",
    "# Filter rows where 'cleavage_window' has 'R' at the fourth position in targetp2_1\n",
    "filtered_df4 = targetp2_1[\n",
    "    targetp2_1['cleavage_window'].str[3] == 'R']\n",
    "output_path_filtered4 = os.path.join(output_folder, f\"{filename.split('.')[0]}_1_R_at_P-3.tsv\")\n",
    "filtered_df4.to_csv(output_path_filtered4, sep='\\t', index=False)\n",
    "print(len(filtered_df4))\n",
    "\n",
    "# Filter rows where 'cleavage_window' has 'R' at the fifth position in targetp2_minus1\n",
    "filtered_df5 = targetp2_minus1[\n",
    "    targetp2_minus1['cleavage_window'].str[4] == 'R']\n",
    "output_path_filtered5 = os.path.join(output_folder, f\"{filename.split('.')[0]}_minus1_R_at_P-2.tsv\")\n",
    "filtered_df5.to_csv(output_path_filtered5, sep='\\t', index=False)\n",
    "print(len(filtered_df5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350387a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming combined_df_without_pyro and targetp2_MT_prediction are already defined as DataFrames\n",
    "df_intensity = combined_df_without_pyro\n",
    "df_intensity_MT = targetp2_MT_prediction\n",
    "\n",
    "# Print the lengths of the dataframes\n",
    "print(f\"Number of rows in df_intensity: {len(df_intensity)}\")\n",
    "print(f\"Number of rows in df_intensity_MT: {len(df_intensity_MT)}\")\n",
    "\n",
    "# Display df_intensity\n",
    "display(df_intensity)\n",
    "\n",
    "# Interactive input for intensity column names\n",
    "intensity_columns_input = input(\n",
    "    'Enter the intensity column names, separated by commas (e.g., \"Light Intensity TAILS1_combined, Heavy Intensity TAILS1_combined\"): '\n",
    ")\n",
    "intensity_columns = [col.strip() for col in intensity_columns_input.split(',')]\n",
    "\n",
    "# Create new columns with log10-transformed values\n",
    "log10_columns = [f'log10_{col}' for col in intensity_columns]\n",
    "df_intensity[log10_columns] = df_intensity[intensity_columns].apply(lambda x: np.log10(x))\n",
    "df_intensity_MT[log10_columns] = df_intensity_MT[intensity_columns].apply(lambda x: np.log10(x))\n",
    "\n",
    "# Interactive input for y-axis limit\n",
    "y_limit_input = input('Enter the y-axis limit for the histograms (e.g., 90): ')\n",
    "y_limit = int(y_limit_input) if y_limit_input else 90\n",
    "\n",
    "# Interactive input for x-axis limit\n",
    "x_limit_input = input('Enter the x-axis limits for the histograms in the format \"min,max\" (e.g., \"4,10\"): ')\n",
    "x_limit = [int(x) for x in x_limit_input.split(',')] if x_limit_input else [4, 10]\n",
    "\n",
    "# Set up subplots for log10-transformed values\n",
    "fig, axes = plt.subplots(nrows=3, ncols=2, figsize=(15, 18))\n",
    "fig.tight_layout(pad=4.0)\n",
    "\n",
    "# Plot histograms for log10-transformed values\n",
    "for i, log10_column in enumerate(log10_columns):\n",
    "    # Extract the current log10-transformed column\n",
    "    log10_values = df_intensity[log10_column]\n",
    "    log10_values_MT = df_intensity_MT[log10_column]\n",
    "    \n",
    "    # Set up the histogram\n",
    "    max_x_value = np.ceil(log10_values.max()) + 1\n",
    "    bin_edges = np.arange(log10_values.min(), max_x_value + 0.1, 0.1)\n",
    "    bin_edges[-1] = max_x_value\n",
    "\n",
    "    # Plot the histogram on the corresponding subplot\n",
    "    row = i // 2\n",
    "    col = i % 2\n",
    "    axes[row, col].hist(log10_values, bins=bin_edges, edgecolor='orange', alpha=0.7, color='orange', label='all_peptides')\n",
    "    axes[row, col].hist(log10_values_MT, bins=bin_edges, edgecolor='red', color='red', label='mitochondrial_peptides')\n",
    "    \n",
    "    # Set labels and title for each subplot\n",
    "    axes[row, col].set_xlabel(f'{log10_column} Intensities', fontsize=16)\n",
    "    axes[row, col].set_ylabel('Count', fontsize=16)\n",
    "    \n",
    "    # Customize y-axis tick labels\n",
    "    axes[row, col].tick_params(axis='y', labelsize=16) \n",
    "    # Customize x-axis tick labels\n",
    "    axes[row, col].tick_params(axis='x', labelsize=16)  \n",
    "    \n",
    "    # Set y-axis limit\n",
    "    axes[row, col].set_ylim(0, y_limit)\n",
    "    # Set x-axis limit\n",
    "    axes[row, col].set_xlim(x_limit)\n",
    "    \n",
    "    # Add legend\n",
    "    legend = axes[row, col].legend(fontsize=16, loc='upper left')\n",
    "    legend.get_frame().set_linewidth(0)  # Remove legend frame\n",
    "    \n",
    "    # Remove left spine\n",
    "    axes[row, col].spines['right'].set_visible(False)\n",
    "    # Remove top spine\n",
    "    axes[row, col].spines['top'].set_visible(False)\n",
    "\n",
    "# Adjust layout\n",
    "plt.subplots_adjust(top=0.9)\n",
    "\n",
    "# Save the figure as a PDF\n",
    "fig_filename = input('Enter the filename for the saved plot (e.g., \"histograms_log10.pdf\"): ')\n",
    "plt.savefig(f\"Figures/{fig_filename}\")\n",
    "\n",
    "# Show the plots\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2da712e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the dataframes\n",
    "df_intensity_all = combined_df_without_pyro\n",
    "df_intensity_targetp2 = targetp2_MT_prediction\n",
    "\n",
    "# Specify the intensity columns\n",
    "#log2_columns = ['Log2 Ratio TAILS1_combined Heavy/Light', 'Log2 Ratio TAILS2_combined Heavy/Light', 'Log2 Ratio TAILS3_combined Heavy/Light']\n",
    "log2_columns = subset_1_cols \n",
    "# Set up subplots\n",
    "fig, axes = plt.subplots(nrows=3, ncols=1, figsize=(7.5, 18))\n",
    "fig.tight_layout(pad=4.0)\n",
    "\n",
    "for i, log2_column in enumerate(log2_columns):\n",
    "    # Extract the current intensity columns\n",
    "    log2_values_targetp2 = df_intensity_targetp2[log2_column]\n",
    "    log2_values_all = df_intensity_all[log2_column]\n",
    "\n",
    "    # Set up the histogram\n",
    "    max_x_value = 7.5\n",
    "    bin_edges = np.arange(min(log2_values_targetp2.min(), log2_values_all.min()), max_x_value + 0.1, 0.1)\n",
    "    bin_edges[-1] = max_x_value  # Set the last bin edge to the maximum x value\n",
    "\n",
    "    # Plot the histogram on the corresponding subplot for all\n",
    "    axes[i].hist(log2_values_all, bins=bin_edges, edgecolor='orange', alpha=0.7, color='orange', label='all_peptides')\n",
    "    axes[i].hist(log2_values_targetp2, bins=bin_edges, edgecolor='red', color='red', label='mitochondrial_peptides')\n",
    "\n",
    "    # Set labels and title for each subplot\n",
    "    axes[i].set_xlabel(f'{log2_column} Ranges', fontsize =16)\n",
    "    axes[i].set_ylabel('Count', fontsize =16)\n",
    "    #axes[i].set_title(f'Histogram of {log2_column}')\n",
    "    \n",
    "     # Customize y-axis tick labels\n",
    "    axes[i].tick_params(axis='y', labelsize=16) \n",
    "    # Customize x-axis tick labels\n",
    "    axes[i].tick_params(axis='x', labelsize=16) \n",
    "    \n",
    "    # Set y-axis limit for all subplots\n",
    "    axes[i].set_ylim(0, 90)\n",
    "    axes[i].set_xlim(-5, 5)\n",
    "    #axes[i].legend(fontsize = 16,loc='upper left')\n",
    "    legend = axes[i].legend(fontsize=16,loc='upper left')\n",
    "    legend.get_frame().set_linewidth(0)  # Remove legend frame\n",
    "    \n",
    "    # Remove left spine\n",
    "    axes[i].spines['right'].set_visible(False)\n",
    "    # Remove top spine\n",
    "    axes[i].spines['top'].set_visible(False)\n",
    "    \n",
    "# Adjust layout\n",
    "plt.subplots_adjust(top=0.9)\n",
    "plt.savefig(\"Figures/histograms_log2_combined.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86130cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate median values for each replicate and normalization category based on all peptides\n",
    "median_values_H_over_L = [statistics.median(combined_df_without_pyro[f'{subset_1_col}'].value_counts().index.to_list()) for subset_1_col in subset_1_cols]\n",
    "print(median_values_H_over_L)\n",
    "\n",
    "# Create a copy of the DataFrame\n",
    "targetp2_MT_prediction_filtered_copy = targetp2_MT_prediction_filtered.copy()\n",
    "\n",
    "# Normalize Log2 Ratio A9/WT\n",
    "for subset_1_col, median_value in zip(subset_1_cols, median_values_H_over_L):\n",
    "    targetp2_MT_prediction_filtered_copy[f'Log2 Ratio noramlized {subset_1_col}'] = (\n",
    "        targetp2_MT_prediction_filtered_copy[f'{subset_1_col}'] - median_value)\n",
    "\n",
    "# Reset index and display the DataFrame\n",
    "targetp2_MT_prediction_filtered_copy = targetp2_MT_prediction_filtered_copy.reset_index(drop=True)\n",
    "\n",
    "# Define column subsets\n",
    "subset_1_cols = [f'Log2 Ratio noramlized {subset_1_col}' for subset_1_col in subset_1_cols]\n",
    "\n",
    "# Extracting column names for light and heavy intensities\n",
    "light_columns = [col for col in targetp2_MT_prediction_filtered_copy.columns if 'Light Intensity' in col]\n",
    "heavy_columns = [col for col in targetp2_MT_prediction_filtered_copy.columns if 'Heavy Intensity' in col]\n",
    "\n",
    "# Calculate mean for light intensity columns and add a new column 'Light Intensity mean'\n",
    "targetp2_MT_prediction_filtered_copy['Light Intensity mean'] = targetp2_MT_prediction_filtered_copy[light_columns].mean(axis=1)\n",
    "\n",
    "# Calculate mean for heavy intensity columns and add a new column 'Heavy Intensity mean'\n",
    "targetp2_MT_prediction_filtered_copy['Heavy Intensity mean'] = targetp2_MT_prediction_filtered_copy[heavy_columns].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0806532",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(targetp2_MT_prediction)\n",
    "\n",
    "# Interactive input for columns\n",
    "light_columns_input = input('Enter the light intensity column names, separated by commas: ').strip().split(',')\n",
    "heavy_columns_input = input('Enter the heavy intensity column names, separated by commas: ').strip().split(',')\n",
    "\n",
    "# Creating boolean masks\n",
    "mask_light = (\n",
    "    targetp2_MT_prediction[light_columns_input].isna().all(axis=1) & \n",
    "    ~targetp2_MT_prediction[heavy_columns_input].isna().any(axis=1)\n",
    ")\n",
    "mask_heavy = (\n",
    "    targetp2_MT_prediction[heavy_columns_input].isna().all(axis=1) &\n",
    "    ~targetp2_MT_prediction[light_columns_input].isna().any(axis=1)\n",
    ")\n",
    "\n",
    "# Creating new dataframes with the filtered rows\n",
    "Peptides_only_in_light_channel = targetp2_MT_prediction[mask_heavy]\n",
    "Peptides_only_in_heavy_channel = targetp2_MT_prediction[mask_light]\n",
    "\n",
    "\n",
    "# Calculating the logarithmic average intensity\n",
    "Peptides_only_in_light_channel['Log2_Avg_Light_Intensity'] = np.log2(\n",
    "    (Peptides_only_in_light_channel[light_columns_input].sum(axis=1)) / len(light_columns_input)\n",
    ")\n",
    "\n",
    "\n",
    "Peptides_only_in_heavy_channel['Log2_Avg_Heavy_Intensity'] = np.log2(\n",
    "    (Peptides_only_in_heavy_channel[heavy_columns_input].sum(axis=1)) / len(heavy_columns_input)\n",
    ")\n",
    "\n",
    "# Create a figure and axis object with decreased width\n",
    "fig, ax = plt.subplots(figsize=(0.5, 6))  # Adjust the width (0.5 inches) and height (6 inches) as needed\n",
    "\n",
    "# Plot the vertical line ranging from 3 to 10\n",
    "vertical_line_x = 5  # x-coordinate for the vertical line\n",
    "vertical_line_y = Peptides_only_in_light_channel['Log2_Avg_Light_Intensity']  # y-coordinates for the vertical line\n",
    "ax.vlines(vertical_line_x, ymin=22, ymax=28, colors='k', linestyles='solid')\n",
    "\n",
    "# Plot the Log10_Avg_Heavy_Intensity values as blue dots on the vertical line with annotations\n",
    "for x, y, protein_id in zip([vertical_line_x] * len(vertical_line_y), vertical_line_y, Peptides_only_in_light_channel['Protein ID']):\n",
    "    ax.plot(x, y, 'bo', markersize=8)  # Increase markersize to 10\n",
    "    #ax.annotate(f'{protein_id}', (x, y), textcoords=\"offset points\", xytext=(5, 0), ha='left', fontsize=8)\n",
    "\n",
    "# Set labels and title\n",
    "ax.set_xlabel('Vertical Line')\n",
    "ax.set_ylabel('log2 Avg_WT_Intensity', fontsize=16)\n",
    "\n",
    "# Set y-axis limit and ticks\n",
    "ax.set_ylim(22, 28)\n",
    "ax.set_yticks(range(22, 28))\n",
    "\n",
    "# Customize y-axis tick labels\n",
    "ax.tick_params(axis='y', labelsize=16) \n",
    "\n",
    "# Hide x-axis and bottom spine\n",
    "ax.xaxis.set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "\n",
    "# Remove right and top spines\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "\n",
    "# Hide grid\n",
    "ax.grid(False)\n",
    "\n",
    "# Save the figure with adjusted bounding box\n",
    "plt.savefig(\"Figures/Peptides_only_in_Light_channel.pdf\", bbox_inches='tight')\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n",
    "\n",
    "# Create the figure for the heavy channel\n",
    "fig, ax = plt.subplots(figsize=(0.5, 6))  # Adjust width and height as needed\n",
    "\n",
    "# Plot the vertical line\n",
    "vertical_line_y = Peptides_only_in_heavy_channel['Log2_Avg_Heavy_Intensity']  # y-coordinates for the vertical line\n",
    "ax.vlines(vertical_line_x, ymin=22, ymax=28, colors='k', linestyles='solid')\n",
    "\n",
    "# Plot the Log2_Avg_Heavy_Intensity values as red dots\n",
    "for x, y, protein_id in zip([vertical_line_x] * len(vertical_line_y), vertical_line_y, Peptides_only_in_heavy_channel['Protein ID']):\n",
    "    ax.plot(x, y, 'ro', markersize=8)  # Change color to red and increase markersize if needed\n",
    "\n",
    "# Set labels and title\n",
    "ax.set_xlabel('Vertical Line')\n",
    "ax.set_ylabel('log2 Avg_Heavy_Intensity', fontsize=16)\n",
    "\n",
    "# Set y-axis limit and ticks\n",
    "ax.set_ylim(22, 28)\n",
    "ax.set_yticks(range(22, 29))\n",
    "\n",
    "# Customize y-axis tick labels\n",
    "ax.tick_params(axis='y', labelsize=16) \n",
    "\n",
    "# Move y-axis to the right side\n",
    "ax.yaxis.tick_right()\n",
    "ax.yaxis.set_label_position(\"right\")\n",
    "\n",
    "# Hide x-axis and bottom spine\n",
    "ax.xaxis.set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "\n",
    "# Remove left spine\n",
    "ax.spines['left'].set_visible(False)\n",
    "\n",
    "# Remove top spine\n",
    "ax.spines['top'].set_visible(False)\n",
    "\n",
    "# Hide grid\n",
    "ax.grid(False)\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig(\"Figures/Peptides_only_in_Heavy_channel.pdf\", bbox_inches='tight')\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741b80fd",
   "metadata": {},
   "source": [
    "now run the R script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f35f1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all \"adj_\" if you want to plot he not adjusted p value\n",
    "# Load the data_final_R.tsv file into a DataFrame\n",
    "data_final = pd.read_csv(\"Output_R.tsv\", sep=\"\\t\")\n",
    "\n",
    "# Extract data for x and y axes, and protein IDs\n",
    "x = data_final['Heavy_over_Light_logFC']\n",
    "y = -np.log10(data_final['adj_p_values_Light_vs_Heavy'])\n",
    "protein_ids = data_final['Protein.ID']\n",
    "protein_descriptions = data_final['Protein.Description']\n",
    "\n",
    "# Filter data points for downregulated proteins (log2 ratio < -1)\n",
    "x_filtered_down = x[(x < -1) & (y > -np.log10(0.05))]\n",
    "y_filtered_down = y[(x < -1) & (y > -np.log10(0.05))]\n",
    "protein_ids_down = protein_ids[(x < -1) & (y > -np.log10(0.05))]\n",
    "protein_descriptions_down = protein_descriptions[(x < -1) & (y > -np.log10(0.05))]\n",
    "\n",
    "# Filter data points for upregulated proteins (log2 ratio > 1)\n",
    "x_filtered_up = x[(x > 1) & (y > -np.log10(0.05))]\n",
    "y_filtered_up = y[(x > 1) & (y > -np.log10(0.05))]\n",
    "protein_ids_up = protein_ids[(x > 1) & (y > -np.log10(0.05))]\n",
    "protein_descriptions_up = protein_descriptions[(x > 1) & (y > -np.log10(0.05))]\n",
    "\n",
    "# Filter data points for proteins with no significant change\n",
    "x_no_change = x[~((x < -1) & (y > -np.log10(0.05))) & ~((x > 1) & (y > -np.log10(0.05)))]\n",
    "y_no_change = y[~((x < -1) & (y > -np.log10(0.05))) & ~((x > 1) & (y > -np.log10(0.05)))]\n",
    "protein_ids_no_change = protein_ids[~((x < -1) & (y > -np.log10(0.05))) & ~((x > 1) & (y > -np.log10(0.05)))]\n",
    "protein_descriptions_no_change = protein_descriptions[~((x < -1) & (y > -np.log10(0.05))) & ~((x > 1) & (y > -np.log10(0.05)))]\n",
    "\n",
    "# Create a DataFrame for downregulated proteins\n",
    "downregulated_data = pd.DataFrame({\n",
    "    'x': x_filtered_down,\n",
    "    'y': y_filtered_down,\n",
    "    'protein_id': protein_ids_down,\n",
    "    'protein_description': protein_descriptions_down,\n",
    "    'change': 'Downregulated'\n",
    "})\n",
    "\n",
    "# Create a DataFrame for upregulated proteins\n",
    "upregulated_data = pd.DataFrame({\n",
    "    'x': x_filtered_up,\n",
    "    'y': y_filtered_up,\n",
    "    'protein_id': protein_ids_up,\n",
    "    'protein_description': protein_descriptions_up,\n",
    "    'change': 'Upregulated'\n",
    "})\n",
    "\n",
    "# Create a DataFrame for proteins with no significant change\n",
    "no_change_data = pd.DataFrame({\n",
    "    'x': x_no_change,\n",
    "    'y': y_no_change,\n",
    "    'protein_id': protein_ids_no_change,\n",
    "    'protein_description': protein_descriptions_no_change,\n",
    "    'change': 'No Change'\n",
    "})\n",
    "\n",
    "# Concatenate the DataFrames\n",
    "combined_data = pd.concat([downregulated_data, upregulated_data, no_change_data])\n",
    "\n",
    "# Add a column 'Signifikant' to data_final based on colors in the volcano plot\n",
    "data_final['Significant'] = np.where((x < -1) & (y > -np.log10(0.05)), 'blue', np.where((x > 1) & (y > -np.log10(0.05)), 'red', 'not significant'))\n",
    "\n",
    "# Create a color dictionary for mapping change types to colors\n",
    "color_dict = {'Downregulated': 'blue', 'Upregulated': 'red', 'No Change': 'grey'}\n",
    "\n",
    "# Create a figure and axis object\n",
    "fig, ax = plt.subplots(figsize=(10, 6))  # Adjust the figure size as needed\n",
    "\n",
    "# Plot data points for downregulated proteins with larger dots\n",
    "ax.scatter(downregulated_data['x'], downregulated_data['y'], color=color_dict['Downregulated'], label='Downregulated', s=50)\n",
    "\n",
    "# Plot data points for upregulated proteins with larger dots\n",
    "ax.scatter(upregulated_data['x'], upregulated_data['y'], color=color_dict['Upregulated'], label='Upregulated', s=50)\n",
    "\n",
    "# Plot data points for proteins with no significant change with larger dots\n",
    "ax.scatter(no_change_data['x'], no_change_data['y'], color=color_dict['No Change'], label='No Change', s=50, alpha =0.5)\n",
    "\n",
    "# Add horizontal line at significance threshold (-log10(0.05))\n",
    "ax.axhline(y=-np.log10(0.05), linestyle='--', color='grey')\n",
    "\n",
    "# Add vertical lines at log2 ratio thresholds (-1 and 1)\n",
    "ax.axvline(x=-1, linestyle='--', color='grey')\n",
    "ax.axvline(x=1, linestyle='--', color='grey')\n",
    "\n",
    "# Set labels and title\n",
    "ax.set_xlabel('log2 Mutant/WT', fontsize=16)\n",
    "ax.set_ylabel('-log10 moderated_adj_p_value', fontsize=16)\n",
    "\n",
    "# Customize y-axis tick labels\n",
    "ax.tick_params(axis='y', labelsize=16) \n",
    "# Customize x-axis tick labels\n",
    "ax.tick_params(axis='x', labelsize=16) \n",
    "# Add legend\n",
    "ax.legend(fontsize = 16, frameon=False)\n",
    "\n",
    "# Remove left spine\n",
    "ax.spines['right'].set_visible(False)\n",
    "# Remove top spine\n",
    "ax.spines['top'].set_visible(False)\n",
    "\n",
    "# Save the figure with adjusted bounding box\n",
    "plt.savefig(\"Figures/Volcano_plot.pdf\")\n",
    "\n",
    "# Reorder columns in final_data DataFrame\n",
    "data_final = data_final[['Peptide.Sequence', 'Modified.Peptide', 'Peptide.Length', 'Protein.ID', 'Protein.Description', \n",
    "                         'Start_Position_in_seq', 'End_Position_in_seq', 'Amino_acid_before_Sequence', 'X6_Amino_acids_before_Sequence', \n",
    "                         'cleavage_window','Start_Position_targetp2','Position_Difference', 'p_values_Light_vs_Heavy', 'adj_p_values_Light_vs_Heavy', \n",
    "                         'Heavy_over_Light_logFC', 'Significant'] + [col for col in data_final.columns if col not in \n",
    "                        ['Peptide.Sequence', 'Modified.Peptide', 'Peptide.Length', 'Protein.ID', 'Protein.Description', \n",
    "                         'Start_Position_in_seq', 'End_Position_in_seq', 'Amino_acid_before_Sequence', 'X6_Amino_acids_before_Sequence', \n",
    "                         'cleavage_window','Start_Position_targetp2','Position_Difference', 'p_values_Light_vs_Heavy', \n",
    "                         'adj_p_values_Light_vs_Heavy', 'Heavy_over_Light_logFC', 'Significant']]]\n",
    "data_final.to_csv('Final_output.tsv', sep='\\t', index=False)\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2109d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data_final_R.tsv file into a DataFrame\n",
    "data_final = pd.read_csv(\"Output_R.tsv\", sep=\"\\t\")\n",
    "\n",
    "# Extract data for x and y axes, and protein IDs\n",
    "x = data_final['Heavy_over_Light_logFC']\n",
    "y = -np.log10(data_final['adj_p_values_Light_vs_Heavy'])\n",
    "protein_ids = data_final['Protein.ID']\n",
    "protein_descriptions = data_final['Protein.Description']\n",
    "\n",
    "# Filter data points for downregulated proteins (log2 ratio < -1)\n",
    "x_filtered_down = x[(x < -1) & (y > -np.log10(0.05))]\n",
    "y_filtered_down = y[(x < -1) & (y > -np.log10(0.05))]\n",
    "protein_ids_down = protein_ids[(x < -1) & (y > -np.log10(0.05))]\n",
    "protein_descriptions_down = protein_descriptions[(x < -1) & (y > -np.log10(0.05))]\n",
    "\n",
    "# Filter data points for upregulated proteins (log2 ratio > 1)\n",
    "x_filtered_up = x[(x > 1) & (y > -np.log10(0.05))]\n",
    "y_filtered_up = y[(x > 1) & (y > -np.log10(0.05))]\n",
    "protein_ids_up = protein_ids[(x > 1) & (y > -np.log10(0.05))]\n",
    "protein_descriptions_up = protein_descriptions[(x > 1) & (y > -np.log10(0.05))]\n",
    "\n",
    "# Filter data points for proteins with no significant change\n",
    "x_no_change = x[~((x < -1) & (y > -np.log10(0.05))) & ~((x > 1) & (y > -np.log10(0.05)))]\n",
    "y_no_change = y[~((x < -1) & (y > -np.log10(0.05))) & ~((x > 1) & (y > -np.log10(0.05)))]\n",
    "protein_ids_no_change = protein_ids[~((x < -1) & (y > -np.log10(0.05))) & ~((x > 1) & (y > -np.log10(0.05)))]\n",
    "protein_descriptions_no_change = protein_descriptions[~((x < -1) & (y > -np.log10(0.05))) & ~((x > 1) & (y > -np.log10(0.05)))]\n",
    "\n",
    "# Create a DataFrame for downregulated proteins\n",
    "downregulated_data = pd.DataFrame({\n",
    "    'x': x_filtered_down,\n",
    "    'y': y_filtered_down,\n",
    "    'protein_id': protein_ids_down,\n",
    "    'protein_description': protein_descriptions_down,\n",
    "    'change': 'Downregulated'\n",
    "})\n",
    "\n",
    "# Create a DataFrame for upregulated proteins\n",
    "upregulated_data = pd.DataFrame({\n",
    "    'x': x_filtered_up,\n",
    "    'y': y_filtered_up,\n",
    "    'protein_id': protein_ids_up,\n",
    "    'protein_description': protein_descriptions_up,\n",
    "    'change': 'Upregulated'\n",
    "})\n",
    "\n",
    "# Create a DataFrame for proteins with no significant change\n",
    "no_change_data = pd.DataFrame({\n",
    "    'x': x_no_change,\n",
    "    'y': y_no_change,\n",
    "    'protein_id': protein_ids_no_change,\n",
    "    'protein_description': protein_descriptions_no_change,\n",
    "    'change': 'No Change'\n",
    "})\n",
    "\n",
    "\n",
    "# Create an interactive volcano plot using Plotly Express\n",
    "fig = px.scatter(combined_data, x='x', y='y', color='change', hover_name='protein_id',\n",
    "                 hover_data={'protein_description': True},\n",
    "                 labels={'x': 'Log2 Fold change Mutant/WT', 'y': '-log10(moderated_adj_p_value)'},\n",
    "                 title='Volcano Plot', width=800, height=600,\n",
    "                 color_discrete_map={'Downregulated': 'blue', 'Upregulated': 'red', 'No Change': 'grey'})\n",
    "\n",
    "# Add horizontal line at significance threshold (-log10(0.05))\n",
    "fig.add_hline(y=-np.log10(0.05), line_dash='dash', line_color='grey')\n",
    "\n",
    "# Add vertical lines at log2 ratio thresholds (-1 and 1)\n",
    "fig.add_vline(x=-1, line_dash='dash', line_color='grey')\n",
    "fig.add_vline(x=1, line_dash='dash', line_color='grey')\n",
    "\n",
    "# Save the plot as an interactive HTML file\n",
    "fig.write_html(\"Figures/Volcano_plot_interactive.html\")\n",
    "\n",
    "# Show plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b8e2fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
